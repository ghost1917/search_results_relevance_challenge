{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "col_types = {u'id': np.int, \n",
    "             u'query': np.str, \n",
    "             u'product_title': np.str,\n",
    "             u'product_description': np.str, \n",
    "             u'relevance': np.int, \n",
    "             u'weight': np.float,\n",
    "             u'median_relevance': np.int, \n",
    "             u'relevance_variance': np.float,\n",
    "             u'q_len' : np.int,\n",
    "             u't_len' : np.int,\n",
    "             u'd_len' : np.int,\n",
    "             u'd_loglen' : np.float,\n",
    "             u'd_exist' : np.int,\n",
    "             u'q_words' : np.int,\n",
    "             u'd_words' : np.int,\n",
    "             u't_words' : np.int,\n",
    "            }\n",
    "train_in = pd.read_csv('clean_train.csv', dtype=col_types)\n",
    "train_in = train_in.fillna (\"\")\n",
    "\n",
    "test  = pd.read_csv('clean_test.csv', dtype=col_types)\n",
    "test = test.fillna (\"\")\n",
    "\n",
    "restored_relevance = pd.read_csv('restored_relevance_train.csv', dtype=col_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим обучающую выборку на train и validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split for train and test\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "rows_ids  = random.sample (train_in.id.unique(), int(train_in.id.nunique()*0.1))\n",
    "validate  = train_in [train_in.id.isin (rows_ids)].copy()\n",
    "train     = train_in [~train_in.id.isin (rows_ids)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве классификатора используем регрессор на случайном лесе.<br>\n",
    "- Регрессор выбран исходя из понимания упорядоченности оценок,\n",
    "- а рендом форест - как один из немногих алгоритмов в scikit learn, поддерживающий веса фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "predictor   = RandomForestRegressor(\n",
    "                                    n_estimators=1000, \n",
    "                                    min_samples_split=30, \n",
    "                                    min_samples_leaf=16, \n",
    "                                    max_depth=10, \n",
    "                                    random_state=None, \n",
    "                                    max_features=None, \n",
    "                                    verbose=0, \n",
    "                                    max_leaf_nodes=None,\n",
    "                                    n_jobs = -1\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расстояние между оценками 4 и 3 может отличаться в реальности от расстояния <br>\n",
    "между 1 и 2 <br>\n",
    "или 2 и 3.\n",
    "\n",
    "Поэтому расстояния между ответами подбирались вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class2regression = {\n",
    "    1:-4,\n",
    "    2:-1,\n",
    "    3:1,\n",
    "    4:4\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ регрессии можно перевести в классы, разделив на 4 диапазона, <br>\n",
    "чтобы количество ответов в каждом было пропорционально <br>\n",
    "числу примеров соответствующего класса в обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.07619610159480213, 0.22150029533372712, 0.3924985233313644, 1]\n"
     ]
    }
   ],
   "source": [
    "# Считаем квантили частот оценок, чтобы переводить по ним результаты регрессии обратно в классы\n",
    "train_qunantiles = [0,\n",
    "                    1. * len (train_in [train_in.median_relevance <=1]) / len (train_in),\n",
    "                    1. * len (train_in [train_in.median_relevance <=2]) / len (train_in),\n",
    "                    1. * len (train_in [train_in.median_relevance <=3]) / len (train_in),\n",
    "                    1]\n",
    "print train_qunantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод выбрасывает из данных все лишние столбцы и превращает матрицу, пригодную для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataset2features (df):\n",
    "    useless_columns = {'id',\n",
    "                       'median_relevance',\n",
    "                     'relevance_variance',\n",
    "                     'query',\n",
    "                     'product_title',\n",
    "                     'product_description',\n",
    "                     'product_description_clauses',\n",
    "                     'relevance',\n",
    "                     'weight',\n",
    "                     'Unnamed: 0'}.intersection (df.columns)\n",
    "    return  df.drop(list (useless_columns), axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем восстановленные метки классов в качестве целевых функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relevance_train = train.merge (restored_relevance, on=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_weights = np.ndarray (buffer = np.array(relevance_train[\"weight\"]), shape = len(relevance_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем предиктор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor.fit(dataset2features(relevance_train), \n",
    "              relevance_train[\"relevance\"].apply (lambda x: class2regression[x]), \n",
    "              np_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказываем результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_prediction  = predictor.predict (dataset2features(train))\n",
    "train_prediction = list(pd.qcut(train_prediction, train_qunantiles, labels=[1,2,3,4]))\n",
    "\n",
    "validate_prediction = predictor.predict (dataset2features(validate))\n",
    "validate_prediction = list(pd.qcut(validate_prediction, train_qunantiles, labels=[1,2,3,4]))\n",
    "\n",
    "test_prediction = predictor.predict (dataset2features(test))\n",
    "test_prediction = list(pd.qcut(test_prediction, train_qunantiles, labels=[1,2,3,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем качество предсказания. Оно получилось завышенным по сравнению с результатами кагла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored relevance\n",
      "train kappa:    0.771919342381\n",
      "validate kappa: 0.675886605114\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "print \"train kappa:   \", utils.quadratic_weighted_kappa (list(train[\"median_relevance\"]),    train_prediction)\n",
    "print \"validate kappa:\", utils.quadratic_weighted_kappa (list(validate[\"median_relevance\"]), validate_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(predictor, open(\"main_predictor.pkl\",'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"id\": test[\"id\"], \n",
    "                           \"prediction\": test_prediction})\n",
    "submission.to_csv(\"results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

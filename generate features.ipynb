{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# basic preprocessing\n",
    "col_types = {u'id': np.int, u'query': np.str, u'product_title': np.str,\n",
    "             u'product_description': np.str, u'median_relevance': np.int, u'relevance_variance': np.float}\n",
    "srt_lowerizer = lambda s: s.lower()\n",
    "\n",
    "convertors = {u'query': srt_lowerizer, u'product_title': srt_lowerizer, u'product_description': srt_lowerizer}\n",
    "\n",
    "df = pd.concat([pd.read_csv('train.csv', dtype=col_types, converters=convertors, index_col=u'id'), \\\n",
    "                pd.read_csv('test.csv',  dtype=col_types, converters=convertors, index_col=u'id')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статистика оценок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x55fc3320>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAYAAAC6d6FnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAGF1JREFUeJzt3X+MXWV+3/H3B4y7uyxdg7Yy5kdlV3IDlmjZUNZVNltm\n",
       "KSC6Sg2VohakEGvVrkotspGiRphtK/JPHdf/ZKH5Z1V2a9MERzSpkEmNA2Tt1UZtmITgjReva7va\n",
       "QditZ4NYIGRbBcqnf8zj+O5kzNyZc+Y+95n7eUmjOee558z5zHPNfOc833sH2SYiIibPJbUDRERE\n",
       "HSkAERETKgUgImJCpQBEREyoFICIiAmVAhARMaEWLQCSfkzSKwMfb0v6kqSrJL0g6aSk5yWtGzjn\n",
       "EUmnJJ2QdNfA+C2SjpXHHlupbyoiIhanpbwPQNIlwFng08DPAW/Y3iPpYeBK2zslbQGeAm4FrgVe\n",
       "BDbbtqRp4CHb05IOAo/bPtTz9xQREUNY6hLQHcBp268D24B9ZXwfcG/ZvgfYb/s92zPAaWCrpA3A\n",
       "Fbany3FPDpwTEREjttQCcB+wv2yvtz1btmeB9WX7GuDMwDlnmLsTmD9+toxHREQFQxcASWuBfwj8\n",
       "5/mPeW4dKX9TIiKiIWuWcOw/AF62/Sdlf1bS1bbPleWd75fxs8D1A+ddx9xv/mfL9uD42fkXkZRC\n",
       "EhGxRLa1nJOG+gB+A9g+sL8HeLhs7wR2l+0twFFgLbAJ+J9caDa/BGwFBBwE7l7gOh4207h9AL9U\n",
       "O0Py18+R/O19tJy95PdyzhvqDkDS5cw1gL84MLwbeFrSPwVmgH9cUhyX9DRwHHgf2OGSENgB7AU+\n",
       "Chz06nsF0MbaATraWDtARxtrB+hoY+0AHW2sHaCDjbUD1DBUAbD9Z8An5429yVxRWOj4XcCuBcZf\n",
       "Bm5aesyIiOhb3gncr721A3S0t3aAjvbWDtDR3toBOtpbO0AHe2sHqGFJbwQbBUn2cpoZERETark/\n",
       "N3MH0CNJU7UzdJH8dSV/PS1n7yIFICJiQmUJKCKicVkCioiIJUkB6FHr64jJX1fy19Ny9i5SACIi\n",
       "JlR6ABERjUsPICIiliQFoEetryMmf13JX0/L2btIAYiImFDpAURENC49gIiIWJIUgB61vo6Y/HUl\n",
       "fz0tZ+8iBSAiYkKlBxAR0bj0ACIiYklSAHrU+jpi8teV/PW0nL2LFICIiAmVHkBEROPSA4iIiCVJ\n",
       "AehR6+uIyV9X8tfTd3ZJHuXHcnMOVQAkrZP0m5K+K+m4pK2SrpL0gqSTkp6XtG7g+EcknZJ0QtJd\n",
       "A+O3SDpWHntsuaEjIsafR/ixPEP1ACTtA75p++uS1gCXA/8KeMP2HkkPA1fa3ilpC/AUcCtwLfAi\n",
       "sNm2JU0DD9melnQQeNz2oXnXSg8gIpo291v5KPurYkV6AJI+AXzW9tcBbL9v+21gG7CvHLYPuLds\n",
       "3wPst/2e7RngNLBV0gbgCtvT5bgnB86JiIgRG2YJaBPwJ5L+o6Q/kvQfJF0OrLc9W46ZBdaX7WuA\n",
       "MwPnn2HuTmD++Nkyvmq0vAYKyV9b8tfTcvYu1gx5zI8zt3TzB5K+AuwcPKAs7/R2vyNpLzBTdt8C\n",
       "jto+Uh6bKtfMfvazn/1e9s/r++vBkfJ5quf989szdLFoD0DS1cB/t72p7P8k8AjwN4DP2T5XlncO\n",
       "275B0k4A27vL8YeAR4HXyjE3lvH7gdtsPzjveukBRETTVk0PwPY54HVJf7MM3QG8CjwLbC9j24Fn\n",
       "yvYB4D5JayVtAjYD0+XrvFNeQSTggYFzIiJixIZ9H8DPAb8u6dvA3wL+LbAbuFPSSeD2so/t48DT\n",
       "wHHgOWCHL9xm7ACeAE4Bp+e/Aqh1ra8jJn9dyV9Py9m7GKYHgO1vM/eyzvnuuMjxu4BdC4y/DNy0\n",
       "lIAREbEy8reAIiJ6tmp6ABERsTqlAPSo9XXE5K8r+etpOXsXKQARERMqPYCIiJ6lBxAREWMtBaBH\n",
       "ra8jJn9dyV9Py9m7SAGIiJhQ6QFERPQsPYCIiBhrKQA9an0dMfnrSv56Ws7eRQpARMSESg8gIqJn\n",
       "6QFERMRYSwHoUevriMlfV/LX03L2LlIAIiImVHoAERE9Sw8gIiLGWgpAj1pfR0z+upK/npazd5EC\n",
       "EBExodIDiIjoWXoAEREx1lIAetT6OmLy15X89bScvYuhCoCkGUl/LOkVSdNl7CpJL0g6Kel5SesG\n",
       "jn9E0ilJJyTdNTB+i6Rj5bHH+v92IiJiWEP1ACR9D7jF9psDY3uAN2zvkfQwcKXtnZK2AE8BtwLX\n",
       "Ai8Cm227FI+HbE9LOgg8bvvQvGulBxARTVuNPYD5X3wbsK9s7wPuLdv3APttv2d7BjgNbJW0AbjC\n",
       "9nQ57smBcyIiYsSGLQAGXpT0h5K+WMbW254t27PA+rJ9DXBm4NwzzN0JzB8/W8ZXjdbXEZO/ruSv\n",
       "p+XsXawZ8rjP2P7fkv4a8IKkE4MPluWd3u53JO0FZsruW8BR20fKY1PlmtnPfvaz38v+eX1/PThS\n",
       "Pk/1vH9+e4Yulvw+AEmPAu8CXwSmbJ8ryzuHbd8gaSeA7d3l+EPAo8Br5Zgby/j9wG22H5z39dMD\n",
       "iIimrZoegKSPSbqibF8O3AUcAw4A28th24FnyvYB4D5JayVtAjYD07bPAe9I2ipJwAMD50RExIgN\n",
       "0wNYD3xL0lHgJeC3bT8P7AbulHQSuL3sY/s48DRwHHgO2OELtxk7gCeAU8Dp+a8Aal3r64jJX1fy\n",
       "19Ny9i4W7QHY/h5w8wLjbwJ3XOScXcCuBcZfBm5aesyIiOhb/hZQRETPVk0PICIiVqcUgB61vo6Y\n",
       "/HUlfz0tZ+8iBSAiYkKlBxAR0bP0ACIiYqylAPSo9XXE5K8r+etpOXsXKQARERMqPYCIiJ6lBxAR\n",
       "EWMtBaBHra8jJn9dyV9Py9m7SAGIiJhQ6QFERPQsPYCIiBhrKQA9an0dMfnrSv56Ws7eRQpARMSE\n",
       "Sg8gIqJn6QFERMRYSwHoUevriMlfV/LX03L2LlIAIiImVHoAERE9Sw8gIiLGWgpAj1pfR0z+upK/\n",
       "npazdzFUAZB0qaRXJD1b9q+S9IKkk5Kel7Ru4NhHJJ2SdELSXQPjt0g6Vh57rP9vJSIilmKoHoCk\n",
       "XwBuAa6wvU3SHuAN23skPQxcaXunpC3AU8CtwLXAi8Bm25Y0DTxke1rSQeBx24cWuFZ6ABHRtFXT\n",
       "A5B0HfB54Ang/AW2AfvK9j7g3rJ9D7Df9nu2Z4DTwFZJG5grHtPluCcHzomIiAqGWQL6FeAXgQ8G\n",
       "xtbbni3bs8D6sn0NcGbguDPM3QnMHz9bxleV1tcRk7+u5K+n5exdrPmwByX9FPB9269cbILK8k6v\n",
       "9zqS9gIzZfct4KjtI+WxqXLd7Gc/+9nvZf+8vr8eHCmfp3reP789Qxcf2gOQtAt4AHgf+AjwV4H/\n",
       "wtwa/5Ttc2V557DtGyTtBLC9u5x/CHgUeK0cc2MZvx+4zfaDC1wzPYCIaNqq6AHY/rLt621vAu4D\n",
       "vmH7AeAAsL0cth14pmwfAO6TtFbSJmAzMG37HPCOpK2SxFxReYaIiKhmqe8DOF/SdgN3SjoJ3F72\n",
       "sX0ceBo4DjwH7PCFW4wdzDWSTwGnF3oFUOtaX0dM/rqSv56Ws3fxoT2AQba/CXyzbL8J3HGR43YB\n",
       "uxYYfxm4aXkxIyKib/lbQBERPVsVPYCIiFi9UgB61Po6YvLXlfz1tJy9ixSAiIgJlR5ARETP0gOI\n",
       "iIixlgLQo9bXEZO/ruSvp+XsXaQARERMqPQAIiJ6lh5ARESMtRSAHrW+jpj8dSV/PS1n7yIFICJi\n",
       "QqUHEBHRs/QAIiJirKUA9Kj1dcTkryv562k5excpABEREyo9gIiInqUHEBERYy0FoEetryMmf13J\n",
       "X0/L2btIAYiImFDpAURE9Cw9gIiIGGspAD1qfR0x+etK/npazt7FhxYASR+R9JKko5KOS/rlMn6V\n",
       "pBcknZT0vKR1A+c8IumUpBOS7hoYv0XSsfLYYyv3LUVExDAW7QFI+pjtH0paA/we8C+BbcAbtvdI\n",
       "ehi40vZOSVuAp4BbgWuBF4HNti1pGnjI9rSkg8Djtg8tcL30ACKiaaumB2D7h2VzLXAp8APmCsC+\n",
       "Mr4PuLds3wPst/2e7RngNLBV0gbgCtvT5bgnB86JiIgKFi0Aki6RdBSYBQ7bfhVYb3u2HDILrC/b\n",
       "1wBnBk4/w9ydwPzxs2V8VWl9HTH560r+elrO3sWaxQ6w/QFws6RPAL8j6XPzHvfc7U5/JO0FZsru\n",
       "W8BR20fKY1PlutnPfvaz38v+eX1/PThSPk/1vH9+e4YulvQ+AEn/Bvg/wD8DpmyfK8s7h23fIGkn\n",
       "gO3d5fhDwKPAa+WYG8v4/cBtth9c4BrpAURE01ZFD0DSJ8+/wkfSR4E7gVeAA8D2cth24JmyfQC4\n",
       "T9JaSZuAzcC07XPAO5K2ShLwwMA5ERFRwWI9gA3AN0oP4CXgWdu/C+wG7pR0Eri97GP7OPA0cBx4\n",
       "DtjhC7cYO4AngFPA6YVeAdS61tcRk7+u5K+n5exdfGgPwPYx4McXGH8TuOMi5+wCdi0w/jJw0/Ji\n",
       "RkRE3/K3gCIierYqegAREbF6pQD0qPV1xOSvK/nraTl7FykAERETKj2AiIiepQcQERFjLQWgR62v\n",
       "IyZ/XclfT8vZu0gBiIiYUOkBRET0LD2AiIgYaykAPWp9HTH560r+elrO3kUKQETEhEoPICKiZ+kB\n",
       "RETEWEsB6FHr64jJX1fy19Ny9i5SACIiJlR6ABERPUsPICIixloKQI9aX0dM/rqSv56Ws3eRAhAR\n",
       "MaHSA4iI6Fl6ABERMdZSAHrU+jpi8teV/PW0nL2LRQuApOslHZb0qqTvSPpSGb9K0guSTkp6XtK6\n",
       "gXMekXRK0glJdw2M3yLpWHnssZX5liIiYhiL9gAkXQ1cbfuopI8DLwP3Al8A3rC9R9LDwJW2d0ra\n",
       "AjwF3ApcC7wIbLZtSdPAQ7anJR0EHrd9aN710gOIiKatmh6A7XO2j5btd4HvMveDfRuwrxy2j7mi\n",
       "AHAPsN/2e7ZngNPAVkkbgCtsT5fjnhw4JyIiRmxJPQBJG4FPAS8B623PlodmgfVl+xrgzMBpZ5gr\n",
       "GPPHz5bxVaP1dcTkryv562k5exdrhj2wLP/8FvDztv9UunC3UZZ3ervfkbQXmCm7bwFHbR8pj02V\n",
       "a2Y/+9nPfi/75/X99eBI+TzV8/757Rm6GOp9AJIuA34beM72V8rYCWDK9rmyvHPY9g2SdgLY3l2O\n",
       "OwQ8CrxWjrmxjN8P3Gb7wXnXSg8gIpq2anoAmvtV/2vA8fM//IsDwPayvR14ZmD8PklrJW0CNgPT\n",
       "ts8B70jaWr7mAwPnRETEiA3TA/gM8DPA5yS9Uj7uBnYDd0o6Cdxe9rF9HHgaOA48B+zwhduMHcAT\n",
       "wCng9PxXALWu9XXE5K8r+etpOXsXi/YAbP8eFy8Ud1zknF3ArgXGXwZuWkrAiIhYGflbQBERPVs1\n",
       "PYCIiFidUgB61Po6YvLXlfz1tJy9i6HfBxARq0+f798pX2/RY7LEOz7SA4iYYK2sVbemlXnNElBE\n",
       "xIRKAehR6+uIyV9X6/l/9M8UtKX9uV+eFICIiAmVHkDEBGtlrbo1rcxr7gAiIiZUCkCPWl9HTP66\n",
       "Ws+fHkB7UgAiIiZUegAx9vp+s9KwJuHfYStr1a1pZV7zTuBoxKhrwKr/GRWRJaA+tb6O2Hr+lteg\n",
       "IfNfU/tzvzwpABEREyo9gBh7o19PhaxVr9gVM68rc8W8DyAiIoaXAtCj1tcRW8/f8ho0ZP5ran/u\n",
       "lycFICJiQqUHEGMvPYCV08padWtamdfcAURETKgUgB61vo7Yev6W16Ah819T+3O/PIsWAElflzQr\n",
       "6djA2FWSXpB0UtLzktYNPPaIpFOSTki6a2D8FknHymOP9f+tRETEUizaA5D0WeBd4EnbN5WxPcAb\n",
       "tvdIehi40vZOSVuAp4BbgWuBF4HNti1pGnjI9rSkg8Djtg8tcL30AOJHpAewclpZq25NK/O66B2A\n",
       "7W8BP5g3vA3YV7b3AfeW7XuA/bbfsz0DnAa2StoAXGF7uhz35MA5ERFRwXJ7AOttz5btWWB92b4G\n",
       "ODNw3Bnm7gTmj58t46tK6+uIredveQ0aMv81tT/3y9P5r4GW5Z1e73Uk7QVmyu5bwFHbR8pjU+W6\n",
       "2Z+g/QuOlM9TK7w/Z1y+/5Xav/A9LzYffe3PZRiX73/+v692/r2e356hi6HeByBpI/DsQA/gBDBl\n",
       "+1xZ3jls+wZJOwFs7y7HHQIeBV4rx9xYxu8HbrP94ALXSg8gfkR6ACunlbXq1rQyr8tdAjoAbC/b\n",
       "24FnBsbvk7RW0iZgMzBt+xzwjqStkgQ8MHBORERUMMzLQPcD/w34MUmvS/oCsBu4U9JJ4Payj+3j\n",
       "wNPAceA5YIcv3GLsAJ4ATgGnF3oFUOtaX0dsPX/La9CQ+a+p/blfnkV7ALbvv8hDd1zk+F3ArgXG\n",
       "XwZuWlK6iIhYMflbQDH20gNYOa2sVbemlXnN/xO4J+Xd0P+owqW/Y/sPKlw3IhqXAtCfDXDZV+Gn\n",
       "/3x0l3z1Mjjxq0AvBWDw5XltOsLgyw1bk/mvp/25X54UgF594j146vLRXW8P8Oiqv52OiJWRvwba\n",
       "q4/8v9oJumj/N6Cp2gE6yfzX0/7cL08KQETEhEoB6NX/vbR2gi7afy30kdoBOsn819P+3C9PCkBE\n",
       "xIRKAehVegB1TdUO0Enmv5725355UgAiIiZUCkCv0gOo60jtAJ1k/utpf+6XJwUgImJCpQD0Kj2A\n",
       "uqZqB+gk819P+3O/PCkAERETKgWgV+kB1HWkdoBOMv/1tD/3y5MCEBExoVIAepUeQF1TtQN0kvmv\n",
       "p/25X54UgIiICZUC0Kv0AOo6UjtAJ5n/etqf++VJAYiImFApAL1KD6CuqdoBOsn819P+3C9PCkBE\n",
       "xIQaeQGQdLekE5JOSXp41NdfWekB1HWkdoBOMv/1tD/3yzPSAiDpUuBXgbuBLcD9km4cZYaV9eet\n",
       "31HdXDtAN0drB+gq819P43O/PKP+gfVp4LTtGdvvAb8B3DPiDCvIrReAdbUDdPNW7QBdZf7raXzu\n",
       "l2fUP7CuBV4f2D9TxiIiYsTWjPh6HvH1RuzdNXD726O73sxfgQ/6nNONPX6tCmZqB+hqY+0A3czU\n",
       "DtDFxtoBapA9up/Jkv4u8Eu27y77jwAf2P53A8es8iIREdE/21rqOaMuAGuA/wH8feB/AdPA/ba/\n",
       "O7IQEREBjHgJyPb7kh4Cfge4FPhafvhHRNQx0juAiIgYH1VetrjYm8EkTUl6W9Ir5eNf18i5EElf\n",
       "lzQr6diHHPN4+d6+LelTo8y3mMXyj/PcA0i6XtJhSa9K+o6kL13kuLF8DobJP67PgaSPSHpJ0lFJ\n",
       "xyX98kWOG9e5XzT/uM79IEmXlmzPXuTx4eff9kg/mFv6Oc1c1/0y5t49cuO8Y6aAA6PONmT+zwKf\n",
       "Ao5d5PHPAwfL9lbg92tnXmL+sZ37ku9q4Oay/XHmekrz//2M7XMwZP6xfQ6Aj5XPa4DfB36ylbkf\n",
       "Mv/Yzv1Axl8Afn2hnEud/xp3AMO+GWzJHe1RsP0t4Acfcsg2YF859iVgnaT1o8g2jCHyw5jOPYDt\n",
       "c7aPlu13ge8C18w7bGyfgyHzw5g+B7Z/WDbXMvfL3JvzDhnbuYeh8sOYzj2ApOuY+yH/BAvnXNL8\n",
       "1ygAw7wZzMBPlFuYg5K2jCxddwt9f9dVyrIczcy9pI3M3c28NO+hJp6DD8k/ts+BpEskHQVmgcO2\n",
       "j887ZKznfoj8Yzv3xa8Avwh8cJHHlzT/NQrAMF3nPwKut/23gX8PPLOykXo3vzK31GlvYu4lfRz4\n",
       "TeDny2/Sf+mQeftj9Rwskn9snwPbH9i+mbkfKn/vIn9EbWznfoj8Yzv3kn4K+L7tV/jwu5Sh579G\n",
       "ATgLXD+wfz1zVeov2P7T87dqtp8DLpN01egidjL/+7uujDWhhbmXdBnwW8Cv2V7oP9Cxfg4Wy9/C\n",
       "c2D7beC/An9n3kNjPffnXSz/mM/9TwDbJH0P2A/cLunJeccsaf5rFIA/BDZL2ihpLfBPgAODB0ha\n",
       "L0ll+9PMvVx1obW6cXQA+Fn4i3c+v2V7tm6k4Y373JdsXwOO2/7KRQ4b2+dgmPzj+hxI+qSkdWX7\n",
       "o8CdwCvzDhvnuV80/7jOPYDtL9u+3vYm4D7gG7Z/dt5hS5r/Uf8tIHyRN4NJ+ufl8a8CPw38C0nv\n",
       "Az9k7psdC5L2A7cBn5T0OvAoc69mwvZXbR+U9HlJp4E/A75QL+1ftlh+xnjui88APwP8saTz//F+\n",
       "Gfjr0MRzsGh+xvc52ADsk3QJc788/ifbvzv43+6Yz/2i+RnfuV+IAbrMf94IFhExoVr/+/UREbFM\n",
       "KQARERMqBSAiYkKlAERETKgUgIiICZUCEBExoVIAIiImVApARMSE+v/f1RwWjzaVWAAAAABJRU5E\n",
       "rkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24f57400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df[~df.median_relevance.isnull()].median_relevance.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем простейшие статистики \n",
    " - длины текстов\n",
    " - наличие описания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['q_len'] = df['query'].apply(lambda s: len(s))\n",
    "df['t_len'] = df['product_title'].apply(lambda s: len(s))\n",
    "df['d_len'] = df['product_description'].apply(lambda s: len(s))\n",
    "df['d_loglen'] = df['product_description'].apply(lambda s: np.log(len(s) + 1))\n",
    "df['d_exist'] = df['product_description'].apply(lambda s: 1.0 if len(s) > 0 else 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Очищаем тексты от html разметки<br>\n",
    "- убираем все нелатинские символы<br>\n",
    "- делим описание на клаузы<br>\n",
    "- нормализуем, убираем стопслова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "nonlatin = re.compile (ur'[^a-zA-Z0-9 ]')\n",
    "space =  re.compile (ur'\\s+')\n",
    "\n",
    "df['query'] = df['query'].apply (lambda x: space.sub(u' ', x))\n",
    "df['query'] = df['query'].apply (lambda x: nonlatin.sub(u'', x))\n",
    "\n",
    "df['product_title'] = df['product_title'].apply (lambda x: BeautifulSoup(x).getText())\n",
    "df['product_title'] = df['product_title'].apply (lambda x: space.sub(u' ', x))\n",
    "df['product_title'] = df['product_title'].apply (lambda x: nonlatin.sub(u'', x))\n",
    "\n",
    "\n",
    "df['product_description'] = df['product_description'].apply (lambda x: BeautifulSoup(x).getText())\n",
    "df['product_description_clauses'] = df['product_description'].apply (lambda x: re.split('[\\n,\\.!?;]', x))\n",
    "df['product_description_clauses'] = df['product_description_clauses'].apply (lambda x: map (lambda y: space.sub(u' ', y), x))\n",
    "df['product_description_clauses'] = df['product_description_clauses'].apply (lambda x: map (lambda y: nonlatin.sub(u'', y), x))\n",
    "df['product_description_clauses'] = df['product_description_clauses'].apply (lambda x: map (lambda y: y.strip(), x))\n",
    "df['product_description_clauses'] = df['product_description_clauses'].apply (lambda x: filter (lambda y:len(y)>0,x))\n",
    "\n",
    "\n",
    "df['product_description'] = df['product_description'].apply (lambda x: space.sub(u' ', x))\n",
    "df['product_description'] = df['product_description'].apply (lambda x: nonlatin.sub(u'', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stopwords_set = set(stopwords.words('english') + ['http','www','img','border','0','1','2','3','4','5','6','7','8','9'])\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def remove_stopwords_and_stem (s):\n",
    "    return ' '.join ([stemmer.stem (w) for w in s.split(' ') if w not in stopwords_set])\n",
    "\n",
    "df['product_description'] = df['product_description'].apply(remove_stopwords_and_stem)\n",
    "df['product_title'] = df['product_title'].apply(remove_stopwords_and_stem)\n",
    "df['query'] = df['query'].apply(remove_stopwords_and_stem)\n",
    "df['product_description_clauses'] = df['product_description_clauses'].apply (lambda x: map(remove_stopwords_and_stem ,x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующие фичи - количество слов, количество клауз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['q_words'] = df['query'].apply (lambda x: len(x.split(' ')))\n",
    "df['d_words'] = df['product_description'].apply (lambda x: len(x.split(' ')))\n",
    "df['t_words'] = df['product_title'].apply (lambda x: len(x.split(' ')))\n",
    "df['d_clauses'] = df['product_description_clauses'].apply (lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Меры близости запроса и заголовка / описания\n",
    "- число слов запроса в заголовке / описании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def a_in_b_cnt (a_set, b_set):\n",
    "    ab_intersection = len(a_set.intersection(b_set))\n",
    "    return 1. * ab_intersection / len(b_set)\n",
    "\n",
    "df[\"q_in_t\"] = df.apply(lambda x: a_in_b_cnt(set(x['query'].split(' ')), \n",
    "                                             set(x['product_title'].split(' '))), axis=1)\n",
    "\n",
    "df[\"q_in_d\"] = df.apply(lambda x: a_in_b_cnt(set(x['query'].split(' ')), \n",
    "                                             set(x['product_description'].split(' '))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- мера жоккара между запросом и заголовком / описанием\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard (a_set, b_set):\n",
    "    ab_intersection = len(a_set.intersection(b_set))\n",
    "    return 1. * ab_intersection / (len(a_set) + len(b_set) - ab_intersection)\n",
    "\n",
    "\n",
    "df[\"q_jac_t\"] = df.apply(lambda x: jaccard(set(x['query'].split(' ')), \n",
    "                                           set(x['product_title'].split(' '))), axis=1)\n",
    "\n",
    "df[\"q_jac_d\"] = df.apply(lambda x: jaccard(set(x['query'].split(' ')), \n",
    "                                           set(x['product_description'].split(' '))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- перекрытие с запросом / описанием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlap (a_set, b_set):\n",
    "    ab_intersection = len(a_set.intersection(b_set))\n",
    "    return 1. * ab_intersection / min(len(a_set),len(b_set))\n",
    "\n",
    "\n",
    "df[\"q_over_t\"] = df.apply(lambda x: overlap(set(x['query'].split(' ')), \n",
    "                                            set(x['product_title'].split(' '))), axis=1)\n",
    "\n",
    "df[\"q_over_d\"] = df.apply(lambda x: overlap(set(x['query'].split(' ')), \n",
    "                                            set(x['product_description'].split(' '))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- косинусная близость в пространстве топиков\n",
    "\n",
    "(расскладывать на топики можно по разному. <br>\n",
    "Сохраняем результаты для 1- и 2-граммов, <br>\n",
    "размерностей пространства топиков от 100 до 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_sim(a_ar, b_ar):\n",
    "    v = (a_ar*b_ar).sum(axis=1)/np.sqrt((a_ar**2).sum(axis=1) * (b_ar**2).sum(axis=1))\n",
    "    v[np.isnan(v)] = 0\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "ngram_range_max_grid = [1, 2]\n",
    "svd_n_components_grid = [100, 200, 300, 400, 500]\n",
    "\n",
    "for ngram_range_max in ngram_range_max_grid:\n",
    "    for svd_n_components in svd_n_components_grid:\n",
    "        print '%i - %i' % (ngram_range_max, svd_n_components)\n",
    "        tfv = TfidfVectorizer(analyzer='word', \n",
    "                              ngram_range=(1, ngram_range_max),\n",
    "                              sublinear_tf=1, \n",
    "                              use_idf=1, \n",
    "                              smooth_idf=1,\n",
    "                              token_pattern=r'\\w{1,}', \n",
    "                              min_df=3)\n",
    "        \n",
    "        all_texts = list([t for t in df['query'].values.tolist() if len(t) > 0])\n",
    "        all_texts.extend([t for t in df['product_title'].values.tolist() if len(t) > 0])\n",
    "        \n",
    "        tfv = tfv.fit(all_texts)\n",
    "        tf_idf_all_texts = tfv.transform(all_texts)\n",
    "        svd = TruncatedSVD(n_components=svd_n_components)\n",
    "        svd = svd.fit(tf_idf_all_texts)\n",
    "\n",
    "        q_nss_tfidf_svd = svd.transform(tfv.transform(df['query'].values.tolist()))\n",
    "        t_nss_tfidf_svd = svd.transform(tfv.transform(df['product_title'].values.tolist()))\n",
    "\n",
    "        df['cos_qt_tfidf%i_svd%i' % (ngram_range_max, svd_n_components)] = cos_sim(q_nss_tfidf_svd, t_nss_tfidf_svd)\n",
    "        df['cos_qt_tfidf%i_svd%i' % (ngram_range_max, svd_n_components)] = \\\n",
    "            df['cos_qt_tfidf%i_svd%i' % (ngram_range_max, svd_n_components)].fillna(0)\n",
    "       \n",
    "        tfv = TfidfVectorizer(analyzer='word', ngram_range=(1, ngram_range_max),\n",
    "                              sublinear_tf=1, use_idf=1, smooth_idf=1,\n",
    "                              token_pattern=r'\\w{1,}', min_df=3)\n",
    "\n",
    "        all_texts = list([t for t in df['query'].values.tolist() if len(t) > 0])\n",
    "        all_texts.extend([t for t in df['product_description'].values.tolist() if len(t) > 0])\n",
    "        \n",
    "        tfv = tfv.fit(all_texts)\n",
    "        tf_idf_all_texts = tfv.transform(all_texts)\n",
    "        \n",
    "        svd = TruncatedSVD(n_components=svd_n_components)\n",
    "        svd = svd.fit(tf_idf_all_texts)\n",
    "\n",
    "        q_nss_tfidf_svd = svd.transform(tfv.transform(df['query'].values.tolist()))\n",
    "        d_nss_tfidf_svd = svd.transform(tfv.transform(df['product_description'].values.tolist()))\n",
    " \n",
    "        df['cos_qd_tfidf%i_svd%i' % (ngram_range_max, svd_n_components)] = cos_sim(q_nss_tfidf_svd, d_nss_tfidf_svd)\n",
    "        df['cos_qd_tfidf%i_svd%i' % (ngram_range_max, svd_n_components)] = \\\n",
    "            df['cos_qd_tfidf%i_svd%i' % (ngram_range_max, svd_n_components)].fillna(0)\n",
    " \n",
    "\n",
    "        ds_nss_tfidf_svd_cos = []\n",
    "        for i in range(df.shape[0]):\n",
    "            if len(df['product_description_clauses'].values[i]) == 0:\n",
    "                ds_nss_tfidf_svd_cos.append(np.array([0]))\n",
    "                continue\n",
    "                \n",
    "            tmp_q = np.repeat(q_nss_tfidf_svd[i, :], \n",
    "                              len(df['product_description_clauses'].values[i]))\\\n",
    "                      .reshape((len(df['product_description_clauses'].values[i]), \n",
    "                                q_nss_tfidf_svd.shape[1]), \n",
    "                               order='F')\n",
    "            tmp_d = svd.transform(tfv.transform(df['product_description_clauses'].values[i]))\n",
    "            \n",
    "            ds_nss_tfidf_svd_cos.append(cos_sim(tmp_q, tmp_d))\n",
    " \n",
    "        df['cos_min_qd_tfidf%i_svd%i' % (ngram_range_max, svd_n_components)] = \\\n",
    "            map(lambda v: np.min(v), ds_nss_tfidf_svd_cos)\n",
    "        df['cos_max_qd_tfidf%i_svd%i' % (ngram_range_max, svd_n_components)] = \\\n",
    "            map(lambda v: np.max(v), ds_nss_tfidf_svd_cos)\n",
    "        df['cos_mean_qd_tfidf%i_svd%i' % (ngram_range_max, svd_n_components)] = \\\n",
    "            map(lambda v: np.mean(v), ds_nss_tfidf_svd_cos)\n",
    "        df['cos_median_qd_tfidf%i_svd%i' % (ngram_range_max, svd_n_components)] = \\\n",
    "            map(lambda v: np.median(v), ds_nss_tfidf_svd_cos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика качества ранжирования okapi bm25 (тоже для N-граммов разной длинны)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Okapi BM25\n",
    "class OkapiBM25:\n",
    "    vectorizer = None\n",
    "    documents_cnt = 1\n",
    "    word_doc_freq = {}\n",
    "    k = 1.5\n",
    "    b = 0.75\n",
    "    avgdl = 0\n",
    "   \n",
    "    def __init__(self, max_n_gram=2, k=1.5, b=0.75):\n",
    "        self.vectorizer = CountVectorizer(analyzer='word', \n",
    "                                          ngram_range=(1, max_n_gram), \n",
    "                                          stop_words=None)\n",
    "        self.k = k        \n",
    "        self.b = b\n",
    "   \n",
    "    def fit(self, X):\n",
    "        self.documents_cnt = X.shape[0]\n",
    "        X = self.vectorizer.fit_transform(X)\n",
    "        self.avgdl = 1. * X.sum() / self.documents_cnt\n",
    "        \n",
    "        self.word_doc_freq = dict(\n",
    "            zip(map(lambda p: p[0], \n",
    "                    sorted(self.vectorizer.vocabulary_.items(), \n",
    "                           key=lambda p: p[1])),\n",
    "                np.array(X.sum(axis=0), \n",
    "                         dtype=np.int).flatten().tolist()))\n",
    "           \n",
    "    def idf(self, w):\n",
    "        n = self.word_doc_freq[w] if w in self.word_doc_freq else 0\n",
    "        return np.log((self.documents_cnt - n + 0.5)/(n + 0.5))\n",
    "   \n",
    "    def f(self, w, d):\n",
    "        return sum(map(lambda x: 1 if x == w else 0, d.split()))\n",
    "   \n",
    "    def score_word(self, w, d):\n",
    "        fqd = self.f(w, d)\n",
    "        return self.idf(w) * (fqd * (self.k + 1))/(fqd + self.k*(1 - self.b + self.b*(len(d.split()))/self.avgdl))\n",
    "   \n",
    "    def score_query(self, q, d):\n",
    "        return sum(map(lambda w: self.score_word(w, d), q.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngram_range_max_grid = range(1, 4)\n",
    "for ngram_range_max in ngram_range_max_grid:\n",
    "    print ngram_range_max\n",
    "   \n",
    "    obm25 = OkapiBM25(max_n_gram=ngram_range_max)\n",
    "    obm25.fit(df['product_title'].values)\n",
    "    df['obm25_%i_qt' % ngram_range_max] = \\\n",
    "        map(lambda p: obm25.score_query(p[0], p[1]), zip(df['query'].values, df['product_title'].values))\n",
    "   \n",
    "    obm25 = OkapiBM25(max_n_gram=ngram_range_max)\n",
    "    obm25.fit(df['product_description'].values)\n",
    "    df['obm25_%i_qd' % ngram_range_max] = \\\n",
    "        map(lambda p: obm25.score_query(p[0], p[1]), zip(df['query'].values, df['product_description'].values))\n",
    "   \n",
    "    sent_scores = map(lambda p: np.array(map(lambda d: obm25.score_query(p[0], d), p[1])),\n",
    "                      zip(df['query'].values, df['product_description_clauses'].values))\n",
    "   \n",
    "    df['obm25_%i_min_qd' % ngram_range_max] = map(lambda v: np.min(v) if len(v) > 0 else 0, sent_scores)\n",
    "    df['obm25_%i_max_qd' % ngram_range_max] = map(lambda v: np.max(v) if len(v) > 0 else 0, sent_scores)\n",
    "    df['obm25_%i_mean_qd' % ngram_range_max] = map(lambda v: np.mean(v) if len(v) > 0 else 0, sent_scores)\n",
    "    df['obm25_%i_median_qd' % ngram_range_max] = map(lambda v: np.median(v) if len(v) > 0 else 0, sent_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- сходство через редакторское расстояние (для поиска опечаток)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def editorDistance (query, text, threshold=0.5):\n",
    "    query_tokens = query.split(\" \")\n",
    "    text_tokens = text.split(\" \")\n",
    "    distance = [[SequenceMatcher (None, qt, tt).ratio() \n",
    "                 for tt in text_tokens] \n",
    "                 for qt in query_tokens] \n",
    "    distance = map (lambda x: max(x), distance)\n",
    "    distance = map (lambda x: 0 if x<threshold else x, distance)\n",
    "    return float(sum(distance))/len(query_tokens)\n",
    "    \n",
    "df['ed_q_to_t'] = df.apply (lambda x: editorDistance(x['query'],x['product_title']), axis = 1)\n",
    "df['ed_q_to_d'] = df.apply (lambda x: editorDistance(x['query'],x['product_description']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кластеризация запросов\n",
    "в обучающей и в тестовой выборке присутствуют одни и те же запросы<br>\n",
    "поэтому можно разделить запросы на группы (кластеризовать) по <br>\n",
    "распределению  ответов на запросы по оценкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_relevance_stat = df[~df.median_relevance.isnull()][['query','median_relevance']]\\\n",
    "                            .groupby (['query','median_relevance'])[\"query\"].count()\n",
    "\n",
    "queries_stat = df[~df.median_relevance.isnull()].groupby(['query'])['query'].count()\n",
    "queries_distribution = queries_relevance_stat.divide(queries_stat, level=0).unstack().fillna(0)\n",
    "\n",
    "# Используем алгоритм кластеризации MeanShift\n",
    "from sklearn.cluster import MeanShift\n",
    "clusterer = MeanShift(bandwidth=0.125)\n",
    "labels    = clusterer.fit_predict(queries_distribution.values)\n",
    "\n",
    "query2cluster = dict (zip (list(queries_distribution.index), list(labels)))\n",
    "df ['query_cluster'] = df['query'].apply(lambda x: query2cluster[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По медиане и дисперсии можно определить, какие оценки выставлялись ассесорами.<br>\n",
    "Используем оценки и их доли для более точной кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Кластеризуем запросы с разложением по релевантности\n",
    "restored_relevance = pd.read_csv('restored_relevance_train.csv', dtype=col_types)\n",
    "\n",
    "query_with_relevance = df [~df.median_relevance.isnull()]\\\n",
    "                            .reset_index()\\\n",
    "                            .merge (restored_relevance, on=\"id\")\\\n",
    "                            [[\"query\", 'relevance', 'weight']]\n",
    "\n",
    "queries_relevance_stat = query_with_relevance.groupby (['query','relevance'])[\"weight\"].sum()\n",
    "queries_stat = query_with_relevance.groupby (['query'])[\"weight\"].sum()\n",
    "\n",
    "queries_distribution = queries_relevance_stat.divide(queries_stat, level=0).unstack().fillna(0)\n",
    "\n",
    "from sklearn.cluster import MeanShift\n",
    "clusterer = MeanShift(bandwidth=0.125)\n",
    "labels    = clusterer.fit_predict(queries_distribution.values)\n",
    "\n",
    "query2cluster = dict (zip (list(queries_distribution.index), list(labels)))\n",
    "df ['query_rel_cluster'] = df['query'].apply(lambda x: query2cluster[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[~df.median_relevance.isnull()].to_csv(\"clean_train.csv\")\n",
    "df[df.median_relevance.isnull()].drop (['median_relevance','relevance_variance'], axis=1).to_csv (\"clean_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
